{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7adab238-7652-4a5e-9d73-8ec1300fc85e",
      "metadata": {
        "id": "7adab238-7652-4a5e-9d73-8ec1300fc85e"
      },
      "outputs": [],
      "source": [
        "#**** Sentiment Analysis using Dutch Tweets****\n",
        "# by SELIM SAMETOGLU\n",
        "# This is a secondary version where I try to implement pipelines from scikitlearn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load dependencies"
      ],
      "metadata": {
        "id": "MCWHmkIoX3z-"
      },
      "id": "MCWHmkIoX3z-"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1fe20592-9190-43b5-a90e-a9a26d4c8449",
      "metadata": {
        "id": "1fe20592-9190-43b5-a90e-a9a26d4c8449",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65e76815-6a0c-489b-dc9f-89ae58297dab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# load the dependencies\n",
        "# Utility\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "# Prepro\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Plotting\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "# sklearn\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "# Has to be installed at each runtime\n",
        "# ! pip install langdetect\n",
        "# to connect to drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XCii0WoiV5LY"
      },
      "id": "XCii0WoiV5LY"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d2e94b06-5d6b-4a93-a87d-942076b9b798",
      "metadata": {
        "id": "d2e94b06-5d6b-4a93-a87d-942076b9b798"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "data = pd.read_json(\"/content/drive/MyDrive/Collab_data/dutch_tweets_chunk0.json\")\n",
        "# Check the lenght of the data\n",
        "# print('number of messages:', len(data))\n",
        "# data[[\"sentiment_pattern\"]].hist()\n",
        "# data[[\"sentiment_pattern\"]]\n",
        "# dichotimize the sentiment categories\n",
        "data.loc[data[\"sentiment_pattern\"] <0, \"sentiment_pattern\"] = 0\n",
        "data.loc[data[\"sentiment_pattern\"] >0, \"sentiment_pattern\"] = 1\n",
        "# check with a histogram whether it worked\n",
        "# data[[\"sentiment_pattern\"]].hist()\n",
        "# take only a small portion of the data for better speed\n",
        "data = data[:1500]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Custom Transformers and Scikit pipelines for preprocessing"
      ],
      "metadata": {
        "id": "xXDUYvtV5c9l"
      },
      "id": "xXDUYvtV5c9l"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### step 1: Create a custom transformer for filtering out 'Non-Dutch' sentences"
      ],
      "metadata": {
        "id": "r3t2yGmiIone"
      },
      "id": "r3t2yGmiIone"
    },
    {
      "cell_type": "code",
      "source": [
        "#  Creating a preprocessing step with\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from langdetect import detect\n",
        "\n",
        "class LanguageFilter(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "# filter out non-Dutch sentences\n",
        "  def detect_language(self, X, y=None):\n",
        "    try:\n",
        "        return detect(X)\n",
        "    except:\n",
        "        return 'unknown'\n",
        "\n",
        "  def fit(self, X, y = None):\n",
        "    return self\n",
        "\n",
        "  def transform(self, X, y= None):\n",
        "    X['language'] = X['full_text'].apply(self.detect_language)\n",
        "    X = X[X['language'] == 'nl']\n",
        "    X.drop('language', axis = 1, inplace = True)\n",
        "    return X"
      ],
      "metadata": {
        "id": "OfVdBoew-yfQ"
      },
      "execution_count": 6,
      "outputs": [],
      "id": "OfVdBoew-yfQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### step 2: column manipulations and turning 'statements into lower case'"
      ],
      "metadata": {
        "id": "wBPwJlr7ZYzt"
      },
      "id": "wBPwJlr7ZYzt"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class CoLo(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  def fit(self, X, y= None):\n",
        "    return self\n",
        "  def transform(self, X, y=None):\n",
        "    X = X[[\"full_text\", \"sentiment_pattern\"]]\n",
        "    X.columns = [\"text\", \"label\"]\n",
        "    X['text'] = X['text'].str.lower()\n",
        "    return X\n"
      ],
      "metadata": {
        "id": "E25BfE_-UJKD"
      },
      "id": "E25BfE_-UJKD",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8-yvIvSpYZSL"
      },
      "id": "8-yvIvSpYZSL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### step 3: clean and remove the stopwords from the text"
      ],
      "metadata": {
        "id": "0Rot69UYYasF"
      },
      "id": "0Rot69UYYasF"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "class Cleaner(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def fit(self, X, y =None):\n",
        "    return self\n",
        "\n",
        "  def transform(self, X, y=None):\n",
        "    stopwordlist = ['aan','al','alles','als', 'altijd','andere', 'ben','bij',\n",
        "    'daar','dan','dat','de','der','deze','die','dit','doch','doen','door','dus',\n",
        "    'een','eens','en','er','ge','geen','geweest','haar','had','heb','hebben','heeft',\n",
        "    'hem','het','hier','hij','hoe','hun','iemand','iets','ik','in','is','ja',\n",
        "    'je','kan','kon','kunnen','maar','me','meer','men','met','mij','mijn','moet',\n",
        "    'na','naar','niet','niets','nog','nu','of','om','omdat','onder','ons','ook',\n",
        "    'op','reeds','te','tegen','toch','toen','tot','u','uit','uw','van','veel','voor',\n",
        "    'want','waren','was','wat','werd','wezen','wie','wil','worden','wordt','zal',\n",
        "    'ze','zelf','zich','zij','zijn','zo','zonder','zou']\n",
        "    STOPWORDS = set(stopwordlist)\n",
        "    X['text'] = X['text'].apply(lambda a: \" \".join([word for word in a.split() if word not in STOPWORDS]))\n",
        "    return X\n"
      ],
      "metadata": {
        "id": "H6HSL5skYynZ"
      },
      "id": "H6HSL5skYynZ",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### step 4: remove punctuations"
      ],
      "metadata": {
        "id": "HABkLM-HT2kP"
      },
      "id": "HABkLM-HT2kP"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "05436d1c-ab2c-4edf-bfe9-523b919c7c23",
      "metadata": {
        "id": "05436d1c-ab2c-4edf-bfe9-523b919c7c23"
      },
      "outputs": [],
      "source": [
        "class RemovePunctuations(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "\n",
        "  def transform(self, X, y=None):\n",
        "    import string\n",
        "    english_punctuations = string.punctuation\n",
        "    punctuations_list = english_punctuations\n",
        "    translator = str.maketrans('', '', punctuations_list)\n",
        "    X['text']=X['text'].str.translate(translator)\n",
        "    return X"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### step 5: remove repeating characters"
      ],
      "metadata": {
        "id": "iTG_wwHvfJmw"
      },
      "id": "iTG_wwHvfJmw"
    },
    {
      "cell_type": "code",
      "source": [
        "class CleaningRepChars(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  def transform(self, X, y=None):\n",
        "    X['text'] = X['text'].apply(lambda a: re.sub(\"(.)\\\\1{2,}\", \"\\\\1\", a))\n",
        "    return X"
      ],
      "metadata": {
        "id": "QzkOHpW0fOzs"
      },
      "id": "QzkOHpW0fOzs",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### step 6: clean and remove URLS\n"
      ],
      "metadata": {
        "id": "bsfA-2r4KYRH"
      },
      "id": "bsfA-2r4KYRH"
    },
    {
      "cell_type": "code",
      "source": [
        "class RemoveURLs(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  def transform(self, X, y=None):\n",
        "    X['text'] = X['text'].apply(lambda a: re.sub('((www.[^s]+)|(https?://[^s]+))',' ', a))\n",
        "    return X"
      ],
      "metadata": {
        "id": "IYf-lMHSKgbN"
      },
      "id": "IYf-lMHSKgbN",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "pipeline = make_pipeline(LanguageFilter(), CoLo(), Cleaner(), RemovePunctuations(), CleaningRepChars(), RemoveURLs())\n",
        "pipeline"
      ],
      "metadata": {
        "id": "-kLrWgynfYqZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "7f263651-58c8-4862-e31e-378422955dce"
      },
      "id": "-kLrWgynfYqZ",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('languagefilter', LanguageFilter()), ('colo', CoLo()),\n",
              "                ('cleaner', Cleaner()),\n",
              "                ('removepunctuations', RemovePunctuations()),\n",
              "                ('cleaningrepchars', CleaningRepChars()),\n",
              "                ('removeurls', RemoveURLs())])"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;languagefilter&#x27;, LanguageFilter()), (&#x27;colo&#x27;, CoLo()),\n",
              "                (&#x27;cleaner&#x27;, Cleaner()),\n",
              "                (&#x27;removepunctuations&#x27;, RemovePunctuations()),\n",
              "                (&#x27;cleaningrepchars&#x27;, CleaningRepChars()),\n",
              "                (&#x27;removeurls&#x27;, RemoveURLs())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;languagefilter&#x27;, LanguageFilter()), (&#x27;colo&#x27;, CoLo()),\n",
              "                (&#x27;cleaner&#x27;, Cleaner()),\n",
              "                (&#x27;removepunctuations&#x27;, RemovePunctuations()),\n",
              "                (&#x27;cleaningrepchars&#x27;, CleaningRepChars()),\n",
              "                (&#x27;removeurls&#x27;, RemoveURLs())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LanguageFilter</label><div class=\"sk-toggleable__content\"><pre>LanguageFilter()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CoLo</label><div class=\"sk-toggleable__content\"><pre>CoLo()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Cleaner</label><div class=\"sk-toggleable__content\"><pre>Cleaner()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RemovePunctuations</label><div class=\"sk-toggleable__content\"><pre>RemovePunctuations()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CleaningRepChars</label><div class=\"sk-toggleable__content\"><pre>CleaningRepChars()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RemoveURLs</label><div class=\"sk-toggleable__content\"><pre>RemoveURLs()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = pipeline.fit_transform(data)"
      ],
      "metadata": {
        "id": "ZyA_Q7_2vAxU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "278894a4-4992-42d5-ef77-243c91fab029"
      },
      "id": "ZyA_Q7_2vAxU",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-9ec160ddf6c9>:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X.drop('language', axis = 1, inplace = True)\n",
            "<ipython-input-7-32e97f6df166>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['text'] = X['text'].str.lower()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4IQ53-X5k95P"
      },
      "id": "4IQ53-X5k95P"
    },
    {
      "cell_type": "code",
      "source": [
        "test\n",
        "# left here 5-July-2023 t - 12:23"
      ],
      "metadata": {
        "id": "pHpNBhEkUQbR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "1009adc5-170c-439b-d852-dd41979600d5"
      },
      "id": "pHpNBhEkUQbR",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  label\n",
              "2     rt ddstandaard droom d66 werkelijkheid covid19...    0.0\n",
              "3     rt ddstandaard droom d66 werkelijkheid covid19...    0.0\n",
              "4     droom d66 werkelijkheid covid19 superdodelijk ...    0.0\n",
              "5     droom d66 werkelijkheid covid19 superdodelijk ...    0.0\n",
              "9     rt frankvanwijck aantal deskundigen over coron...    1.0\n",
              "...                                                 ...    ...\n",
              "1493  rt ojongere ðŸ˜°ðŸ¤¬ corona blijkt stuk harder toe s...    0.0\n",
              "1494  waalse psminister â€œbelgiÃ« gecompliceerd land p...    0.0\n",
              "1495  corona drenthe groningen  jacht mondkapjes gaa...    1.0\n",
              "1496  rt bosm jaap dissel rivm ook nieuw onderzoek s...    1.0\n",
              "1499          rt sbp99 ga liegen lockdown wel voordelen    1.0\n",
              "\n",
              "[1180 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd707f40-0c14-4881-a0c0-fb52286a2887\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rt ddstandaard droom d66 werkelijkheid covid19...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>rt ddstandaard droom d66 werkelijkheid covid19...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>droom d66 werkelijkheid covid19 superdodelijk ...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>droom d66 werkelijkheid covid19 superdodelijk ...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>rt frankvanwijck aantal deskundigen over coron...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1493</th>\n",
              "      <td>rt ojongere ðŸ˜°ðŸ¤¬ corona blijkt stuk harder toe s...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1494</th>\n",
              "      <td>waalse psminister â€œbelgiÃ« gecompliceerd land p...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>corona drenthe groningen  jacht mondkapjes gaa...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>rt bosm jaap dissel rivm ook nieuw onderzoek s...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>rt sbp99 ga liegen lockdown wel voordelen</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1180 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd707f40-0c14-4881-a0c0-fb52286a2887')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dd707f40-0c14-4881-a0c0-fb52286a2887 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dd707f40-0c14-4881-a0c0-fb52286a2887');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "t1iZGa9ud1lr"
      },
      "id": "t1iZGa9ud1lr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8925acab-9e5d-4416-bb72-c1ba553bf1dc",
      "metadata": {
        "id": "8925acab-9e5d-4416-bb72-c1ba553bf1dc"
      },
      "outputs": [],
      "source": [
        "# STEP 7: clean and remove numbers\n",
        "def cleaning_numbers(dataset):\n",
        "    return re.sub('[0-9]+', '', dataset)\n",
        "data['text'] = data['text'].apply(lambda x: cleaning_numbers(x))\n",
        "data['text'].tail() #check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "654304ba-67ac-4787-b65e-52ac0ea79c25",
      "metadata": {
        "id": "654304ba-67ac-4787-b65e-52ac0ea79c25"
      },
      "outputs": [],
      "source": [
        "# STEP 8: tokenization\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "data['text'] = data['text'].apply(tokenizer.tokenize)\n",
        "data['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d410f0b-6eb8-4926-b5a2-2f766dd17a29",
      "metadata": {
        "id": "4d410f0b-6eb8-4926-b5a2-2f766dd17a29"
      },
      "outputs": [],
      "source": [
        "# STEP 9: stemming\n",
        "from nltk.stem.snowball import DutchStemmer\n",
        "\n",
        "st = DutchStemmer()\n",
        "def stemming_on_text(dataset):\n",
        "    text = [st.stem(word) for word in dataset]\n",
        "    return dataset\n",
        "data['text']= data['text'].apply(lambda x: stemming_on_text(x))\n",
        "data['text'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "363aa7d1-beaa-4b18-88cd-e29a46adbc13",
      "metadata": {
        "id": "363aa7d1-beaa-4b18-88cd-e29a46adbc13"
      },
      "outputs": [],
      "source": [
        "# create the 'X' with the features, and create the'y' with the annotations/sentiment\n",
        "X = data['text']\n",
        "y = data['label']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WordClouds"
      ],
      "metadata": {
        "id": "VCS1rxXa2jDs"
      },
      "id": "VCS1rxXa2jDs"
    },
    {
      "cell_type": "code",
      "source": [
        "# Categorize data as positive and negative\n",
        "data_pos = data.loc[data['label'] == 1]\n",
        "data_neg = data.loc[data['label'] == 0]\n",
        "data_pos = data_pos['text']\n",
        "data_neg = data_neg['text']"
      ],
      "metadata": {
        "id": "uVwPdP962f3R"
      },
      "id": "uVwPdP962f3R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word cloud for negative words"
      ],
      "metadata": {
        "id": "da9ZL4EU24da"
      },
      "id": "da9ZL4EU24da"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "870a6aef-6829-4b15-baaf-a19a4a24e41b",
      "metadata": {
        "id": "870a6aef-6829-4b15-baaf-a19a4a24e41b"
      },
      "outputs": [],
      "source": [
        "# Neg word cloud\n",
        "# data_neg = data_neg[:9230]\n",
        "plt.figure(figsize = (20,20))\n",
        "wc_neg = WordCloud(max_words = 1000 , width = 1600 , height = 800,\n",
        "               collocations=False).generate(\" \".join(map(str, data_neg)))\n",
        "plt.imshow(wc_neg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word cloud for positive words"
      ],
      "metadata": {
        "id": "c3L6XhHP2_NK"
      },
      "id": "c3L6XhHP2_NK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52cc1b79-020f-4c06-91e4-850733a054ff",
      "metadata": {
        "id": "52cc1b79-020f-4c06-91e4-850733a054ff"
      },
      "outputs": [],
      "source": [
        "# pos wordcloud\n",
        "# data_pos = data_pos[:17789]\n",
        "plt.figure(figsize = (20,20))\n",
        "wc_pos = WordCloud(max_words = 1000 , width = 1600 , height = 800,\n",
        "               collocations=False).generate(\" \".join(map(str, data_pos)))\n",
        "plt.imshow(wc_pos)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelling"
      ],
      "metadata": {
        "id": "_r6otIDA3Fd9"
      },
      "id": "_r6otIDA3Fd9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the data"
      ],
      "metadata": {
        "id": "VewzL3r23MMJ"
      },
      "id": "VewzL3r23MMJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7374c635-b3b0-4dca-835b-800c57d2a06d",
      "metadata": {
        "id": "7374c635-b3b0-4dca-835b-800c57d2a06d"
      },
      "outputs": [],
      "source": [
        "# Split the data into train and test subsets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.05, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4c43fd2-3997-437c-b34e-2e34e52d337f",
      "metadata": {
        "id": "c4c43fd2-3997-437c-b34e-2e34e52d337f"
      },
      "outputs": [],
      "source": [
        "# Turn data into strings (ensures, otherwise may throw an error)\n",
        "X_train = X_train.astype(str)\n",
        "X_test = X_test.astype(str)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit the TF-IDF Vectorizer"
      ],
      "metadata": {
        "id": "57hNHs9N3Zn7"
      },
      "id": "57hNHs9N3Zn7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a2fa5d9-198d-4d43-bab3-66082c9d7d80",
      "metadata": {
        "id": "3a2fa5d9-198d-4d43-bab3-66082c9d7d80"
      },
      "outputs": [],
      "source": [
        "# Fit the tf-idf vectorizer on the training data (!)\n",
        "vectoriser = TfidfVectorizer(ngram_range=(1, 2), max_features = 500000)\n",
        "vectoriser.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc979f66-308a-433a-b46e-16e7ce62421b",
      "metadata": {
        "id": "bc979f66-308a-433a-b46e-16e7ce62421b"
      },
      "outputs": [],
      "source": [
        "# Check how many feature words are extracted\n",
        "print('No. of feature_words: ', len(vectoriser.get_feature_names_out()))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transform the data according to TF-IDF vectorizer"
      ],
      "metadata": {
        "id": "F4scR5dT3spp"
      },
      "id": "F4scR5dT3spp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f31285fc-7059-4098-b9fb-3dd92593281f",
      "metadata": {
        "id": "f31285fc-7059-4098-b9fb-3dd92593281f"
      },
      "outputs": [],
      "source": [
        "# Transform the data (both train and test data!) using the tf-idf vectorizer\n",
        "X_train = vectoriser.transform(X_train)\n",
        "X_test = vectoriser.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Evaluation"
      ],
      "metadata": {
        "id": "j5GkYqlT39WW"
      },
      "id": "j5GkYqlT39WW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "373be347-106d-4d99-ab90-2f329ff02e24",
      "metadata": {
        "id": "373be347-106d-4d99-ab90-2f329ff02e24"
      },
      "outputs": [],
      "source": [
        "# Define a function for model evaluation\n",
        "# creds to https://www.analyticsvidhya.com/blog/2021/06/twitter-sentiment-analysis-a-nlp-use-case-for-beginners/\n",
        "def model_Evaluate(model):\n",
        "    # Predict values for Test dataset\n",
        "    y_pred = model.predict(X_test)\n",
        "    # Print the evaluation metrics for the dataset.\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    # Compute and plot the Confusion matrix\n",
        "    cf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    categories = ['Negative','Positive']\n",
        "    group_names = ['True Neg','False Pos', 'False Neg','True Pos']\n",
        "    group_percentages = ['{0:.2%}'.format(value) for value in cf_matrix.flatten() / np.sum(cf_matrix)]\n",
        "    labels = [f'{v1}n{v2}' for v1, v2 in zip(group_names,group_percentages)]\n",
        "    labels = np.asarray(labels).reshape(2,2)\n",
        "    sns.heatmap(cf_matrix, annot = labels, cmap = 'Blues',fmt = '',\n",
        "    xticklabels = categories, yticklabels = categories)\n",
        "    plt.xlabel(\"Predicted values\", fontdict = {'size':14}, labelpad = 10)\n",
        "    plt.ylabel(\"Actual values\" , fontdict = {'size':14}, labelpad = 10)\n",
        "    plt.title (\"Confusion Matrix\", fontdict = {'size':18}, pad = 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1: Train and evaluate a Bernoulli Naive Bayes model"
      ],
      "metadata": {
        "id": "CPa73KOf4Sf5"
      },
      "id": "CPa73KOf4Sf5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bae83e3b-34b0-475d-8956-173fe682939b",
      "metadata": {
        "id": "bae83e3b-34b0-475d-8956-173fe682939b"
      },
      "outputs": [],
      "source": [
        "BNBmodel = BernoulliNB()\n",
        "BNBmodel.fit(X_train, y_train)\n",
        "model_Evaluate(BNBmodel)\n",
        "y_pred1 = BNBmodel.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b867c330-9b43-4d35-8ad9-19baf55cfc5e",
      "metadata": {
        "id": "b867c330-9b43-4d35-8ad9-19baf55cfc5e"
      },
      "outputs": [],
      "source": [
        "# Define a function for receiving a ROC curve and RUN it.\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred1)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=1, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC CURVE')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2: Train and evaluate a Linear Support Vector Classification model"
      ],
      "metadata": {
        "id": "u7TT1EFW4tPL"
      },
      "id": "u7TT1EFW4tPL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20b910e1-7238-4c76-b87c-70a5e887078a",
      "metadata": {
        "id": "20b910e1-7238-4c76-b87c-70a5e887078a"
      },
      "outputs": [],
      "source": [
        "SVCmodel = LinearSVC()\n",
        "SVCmodel.fit(X_train, y_train)\n",
        "model_Evaluate(SVCmodel)\n",
        "y_pred2 = SVCmodel.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df9973a6-f8cc-4556-82e7-f6f562aa9152",
      "metadata": {
        "id": "df9973a6-f8cc-4556-82e7-f6f562aa9152"
      },
      "outputs": [],
      "source": [
        "# Define a function for receiving a ROC curve and RUN it.\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred2)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=1, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC CURVE')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 3: Train and evaluate a Logistic regression model"
      ],
      "metadata": {
        "id": "PlJYTCnI5BN2"
      },
      "id": "PlJYTCnI5BN2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d555a998-ea98-412e-a7e9-b865a33357d1",
      "metadata": {
        "id": "d555a998-ea98-412e-a7e9-b865a33357d1"
      },
      "outputs": [],
      "source": [
        "LRmodel = LogisticRegression(C = 2, max_iter = 1000, n_jobs=-1)\n",
        "LRmodel.fit(X_train, y_train)\n",
        "model_Evaluate(LRmodel)\n",
        "y_pred3 = LRmodel.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f61f50a2-9c13-4748-9e38-978d5a2d5f64",
      "metadata": {
        "id": "f61f50a2-9c13-4748-9e38-978d5a2d5f64"
      },
      "outputs": [],
      "source": [
        "# Define a function for receiving a ROC curve and RUN it.\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred3)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=1, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC CURVE')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Overall Interpretation:"
      ],
      "metadata": {
        "id": "g2cChyKc5TjY"
      },
      "id": "g2cChyKc5TjY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c89f8b9b-3d1c-410e-b64a-14800a8e8ae7",
      "metadata": {
        "id": "c89f8b9b-3d1c-410e-b64a-14800a8e8ae7"
      },
      "outputs": [],
      "source": [
        "# The linear support vector classifier (svc) worked the best"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}